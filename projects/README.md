# Projects Overview

## Complete Learning Path: 17 Projects

This directory contains all projects for the ML to LLM learning journey, organized into three phases.

## Phase 1: Classical ML Foundation (Projects 1-11)
**Duration**: 8-12 weeks

Foundation of machine learning concepts:

1. **Linear Regression** - Gradient descent, MSE loss
2. **Logistic Regression** - Classification, sigmoid, cross-entropy
3. **Multi-class Classification** - Softmax, one-hot encoding
4. **Regularization** - Overfitting, L1/L2, bias-variance
5. **Decision Trees** - Non-linear models, feature importance
6. **Random Forests** - Ensembles, bagging
7. **Classification Metrics** - Precision, recall, F1, ROC
8. **Cross-Validation** - K-fold, stratification, hyperparameter tuning
9. **SVMs** - Margin maximization, kernels
10. **Feature Engineering** - Scaling, polynomial features
11. **End-to-End Pipeline** - Complete ML workflow

## Phase 2: Transformers & Pretraining (Projects 12-15)
**Duration**: 4-6 weeks

Understanding transformer architecture and pretraining:

12. **Transformer Architecture** - Build from scratch
13. **Tokenization** - BPE, special tokens, data loaders
14. **Pretraining** ⭐ - Train tiny transformer on Shakespeare
15. **Analysis** - Pretrained vs random comparison

## Phase 3: LLM Fine-tuning (Projects 16-17)
**Duration**: 4-6 weeks

Real-world LLM fine-tuning:

16. **Mistral Instruction Tuning** - LoRA fine-tuning with MLX
17. **Comparative Analysis** - Base vs tuned systematic evaluation

## Project Status

Track your progress:

- [ ] Project 1: Linear Regression
- [ ] Project 2: Logistic Regression
- [ ] Project 3: Multi-class Classification
- [ ] Project 4: Regularization
- [ ] Project 5: Decision Trees
- [ ] Project 6: Random Forests
- [ ] Project 7: Classification Metrics
- [ ] Project 8: Cross-Validation
- [ ] Project 9: SVMs
- [ ] Project 10: Feature Engineering
- [ ] Project 11: End-to-End Pipeline
- [ ] Project 12: Transformer Architecture
- [ ] Project 13: Tokenization
- [ ] Project 14: Pretraining (Core Project)
- [ ] Project 15: Analysis
- [ ] Project 16: Mistral Tuning
- [ ] Project 17: Comparative Analysis

## Navigation

Each project directory contains:
- Jupyter notebook with starter code and structure
- README (for complex projects)
- Data files (as needed)

## Learning Approach

For each project:
1. Read theoretical background
2. Implement from scratch
3. Visualize and experiment
4. Compare with library implementations
5. Document learnings

## Time Management

Suggested time per project:
- Projects 1-4: 3-5 days each
- Projects 5-11: 3-7 days each
- Project 12: 1-2 weeks
- Project 13: 3-5 days
- Project 14: 2-3 weeks (includes training time)
- Project 15: 3-5 days
- Projects 16-17: 2-3 weeks each

## Success Metrics

You're on track if:
- ✓ Can explain concepts without notes
- ✓ Code works from scratch (not copy-paste)
- ✓ Can predict parameter changes
- ✓ Can debug by understanding math
- ✓ Documenting insights, not just completing tasks
